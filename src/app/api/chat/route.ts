import { streamText } from "ai";
import { createOllama } from "ollama-ai-provider-v2";

// Fallback responses when Ollama is not available
const fallbackResponses = [
  "üè¥‚Äç‚ò†Ô∏è Arrgh ! Mon cerveau de pirate num√©rique a besoin d'√™tre recharg√©... R√©essaie dans quelques instants !",
  "‚ö° Mes circuits sont en cours de recalibrage ! Reviens bient√¥t pour une vraie conversation.",
  "üéÉ Oups, je dois mettre √† jour ma connexion neurale. R√©essaie dans un instant !",
  "üîß Mon √©quipe de rongeurs num√©riques r√©pare mes connexions. Patience !",
  "üåä Je suis parti en voyage pirate, reviens plus tard !",
];

// Create Ollama instance - use just the host, Ollama handles the paths
const ollamaBaseURL = "http://ollama:11434/api";
const ollama = createOllama({
  baseURL: ollamaBaseURL,
});

export async function POST(request: Request) {
  try {
    const { message } = await request.json();

    if (!message) {
      return Response.json(
        { error: "Message is required" },
        { status: 400 }
      );
    }

    await fetch(`${ollamaBaseURL}/pull`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model: "mistral",
        stream: false
      }),
    })

    const systemPrompt = `Tu es un avatar IA amusant et bienveillant du projet NIRD. Tu repr√©sentes les valeurs de Num√©rique Inclusif Responsable Durable. 
Tu es enthousiaste, tu utilises parfois des emojis, et tu aimes aider les gens √† comprendre comment contribuer √† un num√©rique plus responsable.
Sois court dans tes r√©ponses (2-3 phrases max), amical et engageant. 
Tu peux parler de sujets vari√©s mais ram√®ne toujours vers NIRD et les missions disponibles.
R√©ponds toujours en fran√ßais.`;

    try {
      const result = streamText({
        model: ollama("mistral"),
        system: systemPrompt,
        prompt: message,
        temperature: 0.7,
      });

      return result.toTextStreamResponse();
    } catch (ollamaError: unknown) {
      const errorMsg = ollamaError instanceof Error ? ollamaError.message : "Unknown error";
      console.warn("Ollama connection failed, using fallback response:", errorMsg);

      // Use a random fallback response
      const fallback = fallbackResponses[Math.floor(Math.random() * fallbackResponses.length)];
      return Response.json({
        response: fallback,
        isOffline: true,
      });
    }
  } catch (error) {
    console.error("Chat error:", error);
    return Response.json(
      {
        error: "Failed to generate response",
        response: "üòÖ Oups, une erreur est survenue...",
      },
      { status: 500 }
    );
  }
}